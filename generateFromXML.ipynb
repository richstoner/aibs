{
 "metadata": {
  "name": "generateFromXML"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Purpose:** To reverse the AIBS api data description and generate a python class scaffold\n",
      "\n",
      "Rich Stoner, 2013\n",
      "\n",
      "This notebook generates a python class for every object listed in the Allen data model. It's a simple scaffold, but it provides a good starting point for developers wanting to work with the AIBS DM.\n",
      "\n",
      "To use the generated files for this module:\n",
      "\n",
      "    from aibs.gen.sectionimage import SectionImage\n",
      "    exampleSectionImage = SectionImage()\n",
      "    \n",
      "To initialize the class, provide a dictionary with key-value pairs for each item\n",
      "\n",
      "    initdata = {}\n",
      "    initdata['path'] = 'AIBSpath.aff'\n",
      "    anotherExampleImage = SectionImage(initialData=initdata)\n",
      "\n",
      "The next steps are:\n",
      "    \n",
      "1. Add utility functions to each class as needed\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, json, urllib2\n",
      "import xmltodict # https://github.com/martinblech/xmltodict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 304
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Download the api description"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xmlDescription = urllib2.urlopen('http://api.brain-map.org/api/v2/data.xml').read()\n",
      "dictDescription = xmltodict.parse(xmlDescription)['Response']['DataDescriptions']['DataDescription']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 305
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure out how many unique field types we need to prepare for"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_types = []\n",
      "\n",
      "from collections import OrderedDict\n",
      "\n",
      "for dd in dictDescription:\n",
      "    ddd = dd[dd.keys()[0]]['fields']['field']\n",
      "    for f in ddd:\n",
      "        if type(f) == type(OrderedDict()):\n",
      "            _type = f['@type']\n",
      "            all_types.append(_type)\n",
      "    \n",
      "unique_types = list(set(all_types))\n",
      "print unique_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'string', u'text', u'float', u'string_array', u'datetime', u'boolean', u'integer_array', u'integer', u'float_array']\n"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write parsers for fields and associations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parseField(f):\n",
      "    baseStr = 'self.%s = ' % (f['@name'])\n",
      "    \n",
      "    if f['@type'] == 'text' or f['@type'] == 'string':\n",
      "        baseStr += '\\'\\''\n",
      "    elif f['@type'] == 'float':\n",
      "        baseStr += '0.0'\n",
      "    elif f['@type'] == 'boolean':\n",
      "        baseStr += 'None'\n",
      "    elif f['@type'] == 'datetime':\n",
      "        baseStr += 'None'\n",
      "    elif f['@type'] == 'integer':\n",
      "        baseStr += '0'\n",
      "    elif 'array' in f['@type']:\n",
      "        baseStr += '[]'\n",
      "    baseStr += '\\n'\n",
      "    return baseStr\n",
      "\n",
      "def parseAssociation(a):\n",
      "    if type(a) == type(OrderedDict()):        \n",
      "        baseStr = 'self.%s = ' % (a['@name'])\n",
      "        \n",
      "        if 'many' in a['@type']:\n",
      "            baseStr += '[]'\n",
      "        else:\n",
      "            baseStr += 'None'\n",
      "            \n",
      "        baseStr += ' # %s %s' % ( a['@type'], a['@class'])\n",
      "        baseStr += '\\n'\n",
      "        return baseStr\n",
      "    else:\n",
      "        return 'ERROR IN CONVERSION'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 274
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that will create the model file for each object type in the api"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createClassFileForDataDescription(dataDescription):\n",
      "       \n",
      "    classname = dataDescription.keys()[0]\n",
      "    filename = '%s.py' % (classname.lower())\n",
      "    \n",
      "#    print classname\n",
      "    \n",
      "    fileString =  '# -*- coding: utf-8 -*-\\n'\n",
      "    fileString += '# Rich Stoner, 2013\\n\\n'\n",
      "    fileString += 'class %s(object):\\n' % (classname)\n",
      "    fileString += '    \\'\\'\\'aibs.model.%s (autogen)\\'\\'\\'\\n\\n' % (classname.lower())\n",
      "    \n",
      "    fileString += ' '*4 + '# Fields\\n'            \n",
      "    \n",
      "    fields = dataDescription[classname]['fields']\n",
      "    \n",
      "    if len(fields) == 1:\n",
      "        ff = fields['field']\n",
      "        if type(ff) == type(OrderedDict()):\n",
      "            fileString += ' '*4 + parseField(ff)            \n",
      "        else:\n",
      "            for field in ff: \n",
      "                fileString += ' '*4 + parseField(field)\n",
      "    else:\n",
      "        pass\n",
      "#        print 'no fields'\n",
      "\n",
      "    fileString += '\\n'        \n",
      "        \n",
      "    fileString += ' '*4 + '# Associations\\n'                \n",
      "    \n",
      "    associations = dataDescription[classname]['associations']\n",
      "    \n",
      "    if type(associations) != type(None):\n",
      "        aa = associations['association']\n",
      "        if type(aa) == type(OrderedDict()):\n",
      "            fileString += ' '*4 + parseAssociation(aa)\n",
      "        else:\n",
      "            for association in aa:\n",
      "                fileString += ' '*4 + parseAssociation(association)\n",
      "    else:\n",
      "#        print '** no associations'\n",
      "        pass\n",
      "\n",
      "        \n",
      "    fileString += '\\n'\n",
      "        \n",
      "    fileString += '    def __init__(self, initialData={}):\\n'\n",
      "    fileString += '        for k,v in initData.iteritems():\\n'\n",
      "    fileString += '            setattr(self, k, v)\\n'\n",
      "    fileString += '        \\n\\n'\n",
      "    fileString += '    # add class methods and private methods here'\n",
      "    \n",
      "    fileToWrite = 'gen/%s' % filename\n",
      "    fout = open(fileToWrite, 'w')\n",
      "    fout.write(fileString)\n",
      "    fout.close()\n",
      "    \n",
      "    #print fileString\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 306
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run it for every model in the api"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n,dd in enumerate(dictDescription):\n",
      "    createClassFileForDataDescription(dd)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 308
    }
   ],
   "metadata": {}
  }
 ]
}